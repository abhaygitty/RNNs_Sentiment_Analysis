{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import os\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import zipfile\n",
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "#file download utilities\n",
    "from six.moves import urllib\n",
    "# from six.moves import xrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.1\n",
      "2.1.2\n",
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)\n",
    "print(mp.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOADED_FILENAME = 'ImdbReviews.tar.gz'\n",
    "\n",
    "def download_file(url_path):\n",
    "    if not os.path.exists(DOWNLOADED_FILENAME):\n",
    "        filename, _ = urllib.request.urlretrieve(url_path, DOWNLOADED_FILENAME)\n",
    "    \n",
    "    print('Found and verified file fom this path: ', url_path)\n",
    "    print('Downloaded file: ', DOWNLOADED_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_REGEX = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def get_reviews(dirname, positive=True):\n",
    "    label = 1 if positive else 0\n",
    "    \n",
    "    reviews = []\n",
    "    labels = []\n",
    "    \n",
    "    for filename in os.listdir(dirname):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(dirname + filename, 'r+', encoding='utf8') as f:\n",
    "                review = f.read()\n",
    "                review = review.lower().replace(\"<br />\", \" \")\n",
    "                review = re.sub(TOKEN_REGEX, '', review)\n",
    "                \n",
    "                # Return a tuple of the review tex and the label\n",
    "                # whether it is a positive or a negative review\n",
    "                #1 - positive review\n",
    "                #0 - negative review\n",
    "                reviews.append(review)\n",
    "                labels.append(label)\n",
    "    return reviews, labels\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels_data():\n",
    "    # If the file has not already been extracted\n",
    "    if not os.path.exists('aclImdb'):\n",
    "        with tarfile.open(DOWNLOADED_FILENAME) as tar:\n",
    "            tar.extractall()\n",
    "            tar.close()\n",
    "    \n",
    "    positive_reviews, positive_labels = get_reviews(\"aclImdb/train/pos/\", positive = True)\n",
    "    negative_reviews, negative_labels = get_reviews(\"aclImdb/train/neg/\", positive = False)\n",
    "    \n",
    "    data = positive_reviews + negative_reviews\n",
    "    labels = positive_labels + negative_labels\n",
    "    \n",
    "    return labels, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified file fom this path:  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "Downloaded file:  ImdbReviews.tar.gz\n"
     ]
    }
   ],
   "source": [
    "URL_PATH = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "download_file(URL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, data = extract_labels_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bromwell high is a cartoon comedy it ran at the same time as some other programs about school life such as teachers my 35 years in the teaching profession lead me to believe that bromwell highs satire is much closer to reality than is teachers the scramble to survive financially the insightful students who can see right through their pathetic teachers pomp the pettiness of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled  at  high a classic line inspector im here to sack one of your teachers student welcome to bromwell high i expect that many adults of my age think that bromwell high is far fetched what a pity that it isnt',\n",
       " 'i liked the film some of the action scenes were very interesting tense and well done i especially liked the opening scene which had a semi truck in it a very tense action scene that seemed well done  some of the transitional scenes were filmed in interesting ways such as time lapse photography unusual colors or interesting angles also the film is funny is several parts i also liked how the evil guy was portrayed too id give the film an 8 out of 10',\n",
       " 'somewhat funny and wellpaced action thriller that has jamie foxx as a hapless fasttalking hoodlum who is chosen by an overly demanding us treasury agent david morse to be released on the streets of new york to find a picky computer thiefhacker doug hutchinson who stole fortytwo million dollars from the treasury and left two guards shot dead  bait marks the sophomore feature for antoine fuqua the replacement killers and he handles the task fairly well even though it doesnt top his first movie what the two films have in common is the action sequences which are flatout excellent  foxx is pretty good here although his character is annoying in the beginning but throughout the film i began to catch on hutchinson is marvelous as the mastermind who can be ruthless as john malkovich and patient as the late laurence olivier was in marathon man morse is okay as the agent who comes up with the ingenious plan to get whoever did it at all cost',\n",
       " 'just two commentsseven years apart hardly evidence of the films relentless pullingpower as has been mentioned the lowbudget telemovie status of 13 gantry row is a mitigating factor in its limited appeal having said that however the thing is not without merit  either as entertainment or as a fright outing per se  true the plot at its most basic is a reworking of the amityville horror  only without much horror more a case of intrigue gibney might have made a more worthwhile impression if she had played halifax investigating a couple of seemingly unconnected murders with the house as the main suspect the script is better than average and the production overall of a high standard it just fails to engage the viewer particularly at key moments  having picked the dvd up for a mere 395 last week at my regular video store i cannot begrudge the expenditure 1095 would be an acceptable price for the film just dont expect fireworks',\n",
       " 'another aussie masterpiece this delves into the world of the unknown and the supernatural and it does very well it doesnt resort to the big special effects overkill like american flicks it focuses more on emotional impact a relatively simple plot that rebecca gibney  co bring to life it follows the story of a couple who buy an old house that was supposedly home to a very old woman who never went outside and whose husband disappeared in mysterious circumstances a century ago strange things begin to happen in the house and john adam begins to turn into the man who disappeared who was actually a mass murderer highly recommended 810']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17957, 17957)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2470\n"
     ]
    }
   ],
   "source": [
    "max_document_length = max([len(x.split(\" \")) for x in data])\n",
    "print(max_document_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 250 #pad the shorter sentence and truncate the longer ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One word represents one time instance and\n",
    "# the memory cell will be unrolled to th enumber of time instances\n",
    "# This has to be the same for all the reviews\n",
    "# A tensprflow function does this processing for us as below for the sequence size provided by us as the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below method transforms every review into its numerical corresponding representation\n",
    "x_data = np.array(list(vocab_processor.fit_transform(data)))\n",
    "\n",
    "y_output = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91987\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(vocab_processor.vocabulary_)\n",
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['just two commentsseven years apart hardly evidence of the films relentless pullingpower as has been mentioned the lowbudget telemovie status of 13 gantry row is a mitigating factor in its limited appeal having said that however the thing is not without merit  either as entertainment or as a fright outing per se  true the plot at its most basic is a reworking of the amityville horror  only without much horror more a case of intrigue gibney might have made a more worthwhile impression if she had played halifax investigating a couple of seemingly unconnected murders with the house as the main suspect the script is better than average and the production overall of a high standard it just fails to engage the viewer particularly at key moments  having picked the dvd up for a mere 395 last week at my regular video store i cannot begrudge the expenditure 1095 would be an acceptable price for the film just dont expect fireworks',\n",
       " 'another aussie masterpiece this delves into the world of the unknown and the supernatural and it does very well it doesnt resort to the big special effects overkill like american flicks it focuses more on emotional impact a relatively simple plot that rebecca gibney  co bring to life it follows the story of a couple who buy an old house that was supposedly home to a very old woman who never went outside and whose husband disappeared in mysterious circumstances a century ago strange things begin to happen in the house and john adam begins to turn into the man who disappeared who was actually a mass murderer highly recommended 810']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[232, 170, 233,  24, 234, 235, 236,  53,  10, 194, 237, 238,  13,\n",
       "        137, 239, 240,  10, 241, 242, 243,  53, 244, 245, 246,   3,   4,\n",
       "        247, 248,  25, 249, 250, 251, 252, 253,  32, 254,  10, 255,   3,\n",
       "        256, 257, 258, 259,  13, 260, 116,  13,   4, 261, 262, 263, 264,\n",
       "        265,  10, 266,   9, 249, 267, 268,   3,   4, 269,  53,  10, 270,\n",
       "        271, 272, 257,  35, 271, 273,   4, 274,  53, 275, 276, 277, 195,\n",
       "        278,   4, 273, 279, 280, 281, 282, 105, 283, 284, 285,   4, 286,\n",
       "         53, 287, 288, 289, 225,  10, 290,  13,  10, 291, 292,  10, 293,\n",
       "          3, 294,  38, 295,  61,  10, 296, 297,  53,   4,   2, 298,   7,\n",
       "        232, 299,  30, 300,  10, 301, 302,   9, 303, 304, 252, 305,  10,\n",
       "        306, 224, 178,   4, 307, 308, 309, 310,   9,  22, 311, 312, 313,\n",
       "         59, 314, 315,  10, 316, 317, 318, 152, 130, 319, 320, 178,  10,\n",
       "         93, 232, 321,  82, 322,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0],\n",
       "       [323, 324, 325, 326, 327, 328,  10, 329,  53,  10, 330,  61,  10,\n",
       "        331,  61,   7, 332,  97, 100,   7, 189, 333,  30,  10, 334, 335,\n",
       "        336, 337, 338, 339, 340,   7, 341, 273, 154, 342, 343,   4, 344,\n",
       "        345, 266,  32, 346, 276, 347, 348,  30,  19,   7, 349,  10, 350,\n",
       "         53,   4, 286,  44, 351, 130, 352, 290,  32, 125, 353, 354,  30,\n",
       "          4,  97, 352, 355,  44, 356, 357, 358,  61, 359, 360, 361,  25,\n",
       "        362, 363,   4, 364, 365, 366, 367, 368,  30, 369,  25,  10, 290,\n",
       "         61, 214, 370, 371,  30, 372, 328,  10, 221,  44, 361,  44, 125,\n",
       "        373,   4, 374, 375, 376, 377, 378,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_output[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(x_data)))\n",
    "\n",
    "x_shuffled = x_data[shuffle_indices]\n",
    "y_shuffled = y_output[shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = 5000\n",
    "TOTAL_DATA = 6000\n",
    "\n",
    "train_data = x_shuffled[:TRAIN_DATA]\n",
    "train_target = y_shuffled[:TRAIN_DATA]\n",
    "\n",
    "test_data = x_shuffled[TRAIN_DATA:TOTAL_DATA]\n",
    "test_target = y_shuffled[TRAIN_DATA:TOTAL_DATA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.int32, [None, MAX_SEQUENCE_LENGTH])\n",
    "y = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 25\n",
    "embedding_size = 50\n",
    "max_label = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "\n",
    "embeddings = tf.nn.embedding_lookup(embedding_matrix, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable_1:0' shape=(91987, 50) dtype=float32_ref>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup_1:0' shape=(?, 250, 50) dtype=float32>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [None, n_steps, n_inputs]\n",
    "# Batch size == number of instances to be fed in at every iteration\n",
    "# steps in time to unroll == the number of discrete time instances for which inputs are available, \n",
    "# dimensionality of input == vector size representing one input at a partiular time instance which is the same as the embedding size\n",
    "# is also the shape reflecting the same in the embeddings above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(embedding_size)\n",
    "# the input parameter - the number of neurons to be in a single memory cell\n",
    "#  Here we have it the same as the embedding size\n",
    "\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell = lstmCell, output_keep_prob = 0.75)\n",
    "# Droptout is used to avoid the model from overfitting\n",
    "# output_keep_probability = 0.75 means that \n",
    "# a neuron in the cell has 75% probablity of being retained and 25% of being removed\n",
    "#  which forces other neurons to learn new features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (encoding, _) = tf.nn.dynamic_rnn(lstmCell, embeddings, dtype=tf.float32)\n",
    "# this simple line of code unrolls the rnn through time\n",
    "#results = output, (final_state, other_state_info)\n",
    "# final_state is of more importance to us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 50) dtype=float32>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the above final_state or the encoding is the output which is fed into \n",
    "# a softmax prediction layer that renders us the \n",
    "# final output whether the review was a positive one or a negative\n",
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the final output has 50 dimensions = embedding_size\n",
    "# embedding_size = number of neurons in one layer of our RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.layers.dense(encoding, max_label, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits, labels = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tf.equal(tf.argmax(logits, 1), tf.cast(y, tf.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam's optimizer is used to minimize the loss. Momentum based optimizer.\n",
    "# gathers momentum as it decents faster down the gradient slope\n",
    "optimizer = tf.train.AdamOptimizer(0.01)\n",
    "train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Test Loss: 0.64, Test Acc: 0.69\n",
      "Epoch: 2, Test Loss: 0.76, Test Acc: 0.668\n",
      "Epoch: 3, Test Loss: 0.87, Test Acc: 0.714\n",
      "Epoch: 4, Test Loss: 0.6, Test Acc: 0.843\n",
      "Epoch: 5, Test Loss: 0.84, Test Acc: 0.841\n",
      "Epoch: 6, Test Loss: 0.83, Test Acc: 0.852\n",
      "Epoch: 7, Test Loss: 0.92, Test Acc: 0.852\n",
      "Epoch: 8, Test Loss: 0.99, Test Acc: 0.849\n",
      "Epoch: 9, Test Loss: 1.0, Test Acc: 0.848\n",
      "Epoch: 10, Test Loss: 1.0, Test Acc: 0.846\n",
      "Epoch: 11, Test Loss: 1.1, Test Acc: 0.843\n",
      "Epoch: 12, Test Loss: 1.1, Test Acc: 0.848\n",
      "Epoch: 13, Test Loss: 1.2, Test Acc: 0.843\n",
      "Epoch: 14, Test Loss: 1.2, Test Acc: 0.849\n",
      "Epoch: 15, Test Loss: 1.3, Test Acc: 0.846\n",
      "Epoch: 16, Test Loss: 1.3, Test Acc: 0.85\n",
      "Epoch: 17, Test Loss: 1.3, Test Acc: 0.847\n",
      "Epoch: 18, Test Loss: 1.3, Test Acc: 0.849\n",
      "Epoch: 19, Test Loss: 1.3, Test Acc: 0.848\n",
      "Epoch: 20, Test Loss: 1.4, Test Acc: 0.849\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        num_batches = int(len(train_data) // batch_size) + 1\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            \n",
    "            min_ix = i * batch_size\n",
    "            max_ix = np.min([len(train_data), ((i+1) * batch_size)])\n",
    "            \n",
    "            x_train_batch = train_data[min_ix:max_ix]\n",
    "            y_train_batch = train_target[min_ix:max_ix]\n",
    "            \n",
    "            train_dict = {x: x_train_batch, y: y_train_batch}\n",
    "            session.run(train_step, feed_dict = train_dict)\n",
    "            \n",
    "            train_loss, train_ac = session.run([loss, accuracy], feed_dict=train_dict)\n",
    "            \n",
    "        test_dict = {x: test_data, y: test_target}\n",
    "        \n",
    "        test_loss, test_acc = session.run([loss, accuracy], feed_dict = test_dict)\n",
    "        print('Epoch: {}, Test Loss: {:.2}, Test Acc: {:.5}'.format(epoch + 1, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = 5000\n",
    "TOTAL_DATA = 6000\n",
    "\n",
    "train_reviews = positive_reviews[:TRAIN_DATA] + negative_reviews[:TRAIN_DATA]\n",
    "\n",
    "test_positive_reviews = positive_reviews[TRAIN_DATA:TOTAL_DATA]\n",
    "test_negative_reviews = negative_reviews[TRAIN_DATA:TOTAL_DATA]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(train_reviews):\n",
    "    words_set = set()\n",
    "    \n",
    "    for review in train_reviews:\n",
    "        words_set.update(review[0].split())\n",
    "    \n",
    "    return list(words_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = get_vocabulary(train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs the data the way our ML model expects it to be\n",
    "def extract_features(review_text):\n",
    "    \n",
    "    #Split the review into words and create a set of words\n",
    "    review_words = set(review_text.split())\n",
    "    \n",
    "    features = {}#dictionary of (word, boolean)\n",
    "    for word in vocabulary:\n",
    "        features[word] = (word in review_words)\n",
    "        #very similar to the one-hot notation\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = nltk.classify.apply_features(extract_features, train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_classifier = nltk.NaiveBayesClassifier.train(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the above line of code will give us a trained Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_calculator(review_text):\n",
    "    features = extract_features(review_text)\n",
    "    return trained_classifier.classify(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_calculator(\"What an amazing moveie!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_calculator(\"Was a great movie until I realised it was not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_calculator(\"wasn't a bad movie I should say\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_calculator(\"was not a bad movie I should say\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_calculator(\"was not a great movie I should say\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_reviews(test_positive_reviews, test_negative_reviews, sentiment_calculator):\n",
    "    \n",
    "    positive_results = [sentiment_calculator(review[0]) for review in test_positive_reviews]\n",
    "    negative_results = [sentiment_calculator(review[0]) for review in test_negative_reviews]\n",
    "    \n",
    "    true_positives = sum(x > 0 for x in positive_results)\n",
    "    true_negatives = sum(x == 0 for x in negative_results)\n",
    "    \n",
    "    percent_true_positive = float(true_positives/len(positive_results))\n",
    "    percent_true_negative = float(true_negatives/len(negative_results))\n",
    "    \n",
    "    total_accurate = true_positives + true_negatives\n",
    "    total = len(positive_results) + len(negative_results)\n",
    "    \n",
    "    print(\"Accuracy on positive reviews = \" + \"%.2f\" % (percent_true_positive * 100) + \"%\")\n",
    "    print(\"Accuracy on negative reviews = \" + \"%.2f\" % (percent_true_negative * 100) + \"%\")\n",
    "    print(\"Overall accuracy = \" + \"%.2f\" % (total_accurate * 100/ total) + \"%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_test_reviews(test_positive_reviews, test_negative_reviews, sentiment_calculator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
